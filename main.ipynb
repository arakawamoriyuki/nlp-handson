{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0605 21:39:50.865039 140182359365376 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tf_sentencepiece\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "import keras.layers as layers\n",
    "import keras.optimizers as optimizers\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "csv_path = './datasets.csv'\n",
    "datasets = {}\n",
    "with open(csv_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for index, row in enumerate(reader):\n",
    "        collected_row = [sentence for sentence in row if not sentence == '']\n",
    "        print(index)\n",
    "        if collected_row[0] in datasets:\n",
    "            raise\n",
    "        # 先頭をlabelとする\n",
    "        datasets[collected_row[0]] = collected_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, sentences in datasets.items():\n",
    "    labels.append(key)\n",
    "    label_index = labels.index(key)\n",
    "    for sentence in sentences:\n",
    "        x_train.append(sentence)\n",
    "        y_train.append(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ファッション', '帽子買いたい', 'ジーパン欲しい'], [0, 0, 0], ['ファッション', 'スーパー', 'レストラン'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:3], y_train[0:3], labels[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(x_train, y_train))\n",
    "shuffle(train_data)\n",
    "x_train = [d[0] for d in train_data]\n",
    "y_train = [d[1] for d in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ランチどこにしよう', 'お腹ぺこぺこ', 'お手洗いはどこですか'], [2, 2, 4], ['ファッション', 'スーパー', 'レストラン'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:3], y_train[0:3], labels[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np_utils.to_categorical(np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ランチどこにしよう', 'お腹ぺこぺこ', 'お手洗いはどこですか'], dtype='<U11'),\n",
       " array([[0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0.]], dtype=float32),\n",
       " ['ファッション', 'スーパー', 'レストラン'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:3], y_train[0:3], labels[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model_path = 'models/usex.h5'\n",
    "log_path = 'logs/tboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# model = load_model(model_path, custom_objects={'USEXEmbeddingLayer': USEXEmbeddingLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define EmbeddingLayer\n",
    "class USEXEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.name = 'USEXEmbeddingLayer'\n",
    "        self.trainable = kwargs['trainable'] if 'trainable' in kwargs else False\n",
    "        super(USEXEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.usex = hub.Module(\n",
    "            'https://tfhub.dev/google/universal-sentence-encoder-xling-many/1',\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name),\n",
    "        )\n",
    "        super(USEXEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.usex(\n",
    "            K.squeeze(K.cast(x, K.tf.string), axis=1),\n",
    "            as_dict=True,\n",
    "            signature='default',\n",
    "        )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0605 21:40:16.675343 140182359365376 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "inputs = layers.Input(shape=(1,), dtype='string')\n",
    "outputs = USEXEmbeddingLayer()(inputs)\n",
    "outputs = layers.Dense(512, activation='relu')(outputs)\n",
    "outputs = layers.BatchNormalization()(outputs)\n",
    "outputs = layers.Dropout(0.5)(outputs)\n",
    "outputs = layers.Dense(512, activation='relu')(outputs)\n",
    "outputs = layers.BatchNormalization()(outputs)\n",
    "outputs = layers.Dropout(0.5)(outputs)\n",
    "outputs = layers.Dense(len(labels), activation='softmax')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "usex_embedding_layer_1 (USEX (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 532,999\n",
      "Trainable params: 530,951\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[inputs], outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=optimizers.rmsprop(\n",
    "        lr=0.001,\n",
    "        rho=0.9,\n",
    "        epsilon=None,\n",
    "        decay=0.0,\n",
    "    ),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 4s 106ms/step - loss: 3.0265 - acc: 0.1892 - val_loss: 1.5435 - val_acc: 0.4000\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9574 - acc: 0.7297 - val_loss: 1.8739 - val_acc: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e3405f7b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor='val_acc',\n",
    "            patience=1,\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3,\n",
    "            patience=1,\n",
    "        ),\n",
    "        TensorBoard(\n",
    "            log_dir=log_path,\n",
    "            write_graph=True,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "sentence = 'ディナーどこにしよう'\n",
    "\n",
    "results = model.predict(np.array([sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.5663622e-05, 1.8084531e-03, 9.8588967e-01, 1.1055422e-02,\n",
       "        1.6937029e-04, 6.2369945e-04, 3.7769103e-04]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.59%:レストラン\n",
      "1.11%:コンビニ\n",
      "0.18%:スーパー\n"
     ]
    }
   ],
   "source": [
    "result = results[0]\n",
    "indexes = list(range(len(labels)))\n",
    "predictions = dict(zip(indexes, result))\n",
    "predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "predictions = predictions[0:3]\n",
    "for prediction in predictions:\n",
    "    label = labels[prediction[0]]\n",
    "    score = '{:.2%}'.format(prediction[1])\n",
    "    print('{}:{}'.format(score, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicter(model, labels):\n",
    "    indexes = list(range(len(labels)))\n",
    "\n",
    "    def predicter(sentences):\n",
    "        results = model.predict(np.array(sentences))\n",
    "        for sentence_index, result in enumerate(results):\n",
    "            sentence = sentences[sentence_index]\n",
    "            print('====================')\n",
    "            print('q: {}'.format(sentence))\n",
    "            predictions = dict(zip(indexes, result))\n",
    "            predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "            predictions = predictions[0:5]\n",
    "            for prediction in predictions:\n",
    "                index = prediction[0]\n",
    "                label = labels[index]\n",
    "                score = prediction[1]\n",
    "                print('\\n----------\\nscore:{}\\n{}'.format('{:.2%}'.format(score), label))\n",
    "\n",
    "    return predicter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicter = generate_predicter(model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "q: 車が壊れた\n",
      "\n",
      "----------\n",
      "score:98.79%\n",
      "ガゾリンスタンド\n",
      "\n",
      "----------\n",
      "score:1.11%\n",
      "レストラン\n",
      "\n",
      "----------\n",
      "score:0.04%\n",
      "コンビニ\n",
      "\n",
      "----------\n",
      "score:0.03%\n",
      "トイレ\n",
      "\n",
      "----------\n",
      "score:0.01%\n",
      "病院\n"
     ]
    }
   ],
   "source": [
    "predicter(['車が壊れた'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0605 21:41:02.820655 140182359365376 tf_logging.py:125] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0605 21:41:02.822668 140182359365376 tf_logging.py:115] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0605 21:41:02.824419 140182359365376 tf_logging.py:115] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: models/serving/1/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0605 21:41:18.131458 140182359365376 tf_logging.py:115] SavedModel written to: models/serving/1/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# save pb\n",
    "serving_model_path = 'models/serving/1'\n",
    "tf.saved_model.simple_save(\n",
    "    K.get_session(),\n",
    "    serving_model_path,\n",
    "    inputs={'inputs': model.input},\n",
    "    outputs={t.name: t for t in model.outputs},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
